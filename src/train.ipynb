{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from connection import create_spotify_oauth, get_audio_features, get_token, get_tracks, \\\n",
    "    tracks_to_df, audio_features_to_df, get_artist_info, artist_info_to_df, get_album_info, \\\n",
    "        album_info_to_df, get_similar_artists\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "import json\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, Normalizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token and authentication variables\n",
    "\n",
    "sp_ouath = create_spotify_oauth()\n",
    "token_info = get_token()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting playlist items\n",
    "\n",
    "playlist_source = '5tsD40JmH6fgIrguJdJ8tk' # playlist id for playlist\n",
    "\n",
    "# playlists id's to play around with: \n",
    "### 5a4unKpRA7mYi2PAgKTuNW\n",
    "### 7jfRuO7rW49RJnafrxsJeu\n",
    "### 2YWkEfOW4TG0njIeLqFk4B\n",
    "### 02dSgnwgoovYRH6RlptgDC\n",
    "### 5EGXIeHfAZjPh1YeVLyG13\n",
    "### 5tsD40JmH6fgIrguJdJ8tk\n",
    "###\n",
    "\n",
    "tracks = get_tracks(playlist_source, token_info) # parses Spotipy.playlist_items() to fetch playlist items\n",
    "tracks_df = tracks_to_df(tracks) # extracts relevant features from messy list into a df\n",
    "\n",
    "# drops duplicate songs based on track ID, this is useful if a song gets added from single and \n",
    "# album release; or in the case of deluxe versions of albums, etc.\n",
    "tracks_df.drop_duplicates(subset=['track_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting tracks' features\n",
    "\n",
    "tracks_features = []\n",
    "\n",
    "for track in tracks_df['track_id']:\n",
    "    track_af = get_audio_features(track, token_info) # parses Spotipy.audio_features() to fetch track features\n",
    "    tracks_features.extend(track_af) # extends each track's features into the empty list init'd before\n",
    "    \n",
    "tracks_features_df = audio_features_to_df(tracks_features) # converts nested data from API call to simple df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting tracks' artists\n",
    "\n",
    "tracks_artists = []\n",
    "\n",
    "for artist_id in tracks_df['artist_id']:\n",
    "    for i in artist_id: # since one track can have multiple artists, loop over the list of artists to pull data for each one\n",
    "        artist_info = get_artist_info(i, token_info)\n",
    "        tracks_artists.append(artist_info)\n",
    "\n",
    "artists_df = artist_info_to_df(tracks_artists) # converts nested data to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting tracks' albums\n",
    "\n",
    "tracks_albums = []\n",
    "\n",
    "for album_id in tracks_df['album_id']:\n",
    "    album_info = get_album_info(album_id, token_info)\n",
    "    tracks_albums.append(album_info)\n",
    "\n",
    "albums_df = album_info_to_df(tracks_albums) # converts nested data to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing tracks dataframe\n",
    "\n",
    "# merging features df to track df\n",
    "tracks_df.drop(['album_cover_640', 'album_cover_300', 'album_cover_64'], axis=1, inplace=True)\n",
    "tracks_df = pd.merge(tracks_df, tracks_features_df, how='left')\n",
    "\n",
    "# binarizing explicit column\n",
    "tracks_df['explicit'] = tracks_df['explicit'].replace({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing artists dataframe\n",
    "\n",
    "# lambda converts the columns into strings and strips of the exterior [] and '' using re, then splits the string \n",
    "# into a list based on ','\n",
    "artists_df['artist_genres'] = artists_df['artist_genres'].apply(lambda x: re.sub(r\"[\\[\\]']\", '', str(x)).split(','))\n",
    "\n",
    "# unnest the list of genres into seperate rows, rest of features are duplicated\n",
    "artists_df = artists_df.explode('artist_genres')\n",
    "\n",
    "# creates a copy of artist_df where there are no genres then drops those rows from the original df\n",
    "artists_missing_genres = artists_df.loc[artists_df['artist_genres'] == \"\"].copy()\n",
    "artists_df = artists_df[artists_df['artist_genres'] != '']\n",
    "\n",
    "# check for any artists that have missing genres\n",
    "if not artists_df.loc[artists_df['artist_genres'] == ''].empty:\n",
    "    \n",
    "    # iterates through the rows of the dataframe\n",
    "    for index, artist in artists_missing_genres.iterrows():\n",
    "        artist_id = artist['artist_id']\n",
    "        similar_artists = get_similar_artists(artist_id, token_info) # API call\n",
    "        \n",
    "        # list comprehension that fetches the artist genres for every similar artist    \n",
    "        genres_list = [similar_artist['genres'] for similar_artist in similar_artists if similar_artist['genres']]\n",
    "        \n",
    "    # convert the loop output to list\n",
    "    flattened_genres = list(chain.from_iterable(genres_list))\n",
    "\n",
    "    # converting to set so only unique values remain in list and adding it to the artists_missing_genres df\n",
    "    artists_missing_genres.at[index, 'artist_genres'] = list(set(flattened_genres)) \n",
    "\n",
    "    artists_missing_genres = artists_missing_genres.explode('artist_genres')\n",
    "\n",
    "    # if after imputation, there are still no genres, mark it off as not imputable\n",
    "    artists_missing_genres['artist_genres'].replace('','genre not imputable', inplace=True)\n",
    "\n",
    "    # concat the missing artist genres with the original df\n",
    "    artists_df = pd.concat([artists_df, artists_missing_genres], ignore_index=False)\n",
    "\n",
    "# dropping  duplicate records, this occurs if a playlist has multiple tracks from the same artist\n",
    "artists_df.drop_duplicates(subset=['artist_id', 'artist_genres'], inplace=True)\n",
    "\n",
    "genres_df = artists_df['artist_genres'].copy() # isolate genres\n",
    "\n",
    "# undo the explosions of genres in above steps (yes a bit redundant but wtv for now)\n",
    "artists_df = artists_df.groupby(['artist_followers', 'artist_popularity', 'artist_img_300']).agg({'artist_id': 'first'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing albums dataframe\n",
    "\n",
    "# converting object type column to datetime\n",
    "albums_df['album_release_date'] = pd.to_datetime(albums_df['album_release_date'], format=\"mixed\")\n",
    "albums_df['album_release_date'] = albums_df['album_release_date'].dt.year # keeping only YYYY info\n",
    "\n",
    "# categorizing album type column\n",
    "albums_df['album_type'] = albums_df['album_type'].replace({'single': 0, 'album': 1, 'compilation': 2}) # EP's count as singles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping columns together by type\n",
    "\n",
    "tracks_cols = {\n",
    "    'id_cols': ['track_id', 'album_id', 'artist_id'],\n",
    "    'display_cols': ['track_name', 'preview_url'],\n",
    "    'binary_cols': ['explicit', 'mode'],\n",
    "    'ranged_cols': ['song_popularity', 'danceability', 'energy', 'loudness', 'speechiness', \n",
    "                  'acousticness', 'instrumentalness', 'liveness','valence'],\n",
    "    'discrete_cols': ['artist_number'],\n",
    "    'continuous_cols': ['tempo', 'duration_ms'],\n",
    "    'ordinal_cols': ['key', 'time_signature']\n",
    "}\n",
    "\n",
    "artists_cols = {\n",
    "    'id_cols': ['artist_id'],\n",
    "    'display_cols': ['artist_name', 'artist_img_300'],\n",
    "    'ranged_cols': ['artist_popularity'],\n",
    "    'continuous_cols': ['artist_followers'],\n",
    "    'ordinal_cols': []  # making an empty list for simplicity's sake in some code down below\n",
    "}\n",
    "\n",
    "albums_cols = {\n",
    "    'id_cols': ['album_id'],\n",
    "    'display_cols': ['album_name', 'album_label', 'album_cover_640', 'album_cover_300', 'album_cover_64'],\n",
    "    'ranged_cols': ['album_popularity'],\n",
    "    'discrete_cols': ['album_tracks'],\n",
    "    'ordinal_cols': ['album_release_date'],\n",
    "    'cat_lai_cols': ['album_type'],  # leave as is\n",
    "    'continuous_cols': []\n",
    "}\n",
    "\n",
    "# creating filtered down df's for each group using list comprehensions that excludes id and display cols.\n",
    "# essentially it grabs every col in the df and checks if those cols are not part of id/display\n",
    "tracks_to_transform = tracks_df[[col for col in tracks_df.columns if col not in tracks_cols['id_cols'] + tracks_cols['display_cols']]]\n",
    "artists_to_transform = artists_df[[col for col in artists_df.columns if col not in artists_cols['id_cols'] + artists_cols['display_cols']]]\n",
    "albums_to_transform = albums_df[[col for col in albums_df.columns if col not in albums_cols['id_cols'] + albums_cols['display_cols']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracks_df visualizations\n",
    "\n",
    "# numerical features to plot \n",
    "tracks_cols_to_plot = ['artist_number', 'song_popularity', 'danceability', 'energy',\n",
    "                'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness',\n",
    "                'liveness', 'valence', 'tempo', 'duration_ms', 'time_signature']\n",
    "\n",
    "# histogram visualizations of numerical track_df features\n",
    "num_cols = 3\n",
    "num_rows = len(tracks_cols_to_plot) // num_cols + (len(tracks_cols_to_plot) % num_cols > 0) \n",
    "\n",
    "plt.figure(figsize=(15, 15)) # creates grid\n",
    "\n",
    "# iterates through the list and creates a histogram subplot \n",
    "for i, column in enumerate(tracks_cols_to_plot, 1):\n",
    "    plt.subplot(num_rows, num_cols, i) \n",
    "    tracks_df[column].plot.hist()\n",
    "    plt.title(column)\n",
    "\n",
    "plt.tight_layout() # smushes them together\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# boxplot visualizations of numerical track_df features, pretty much same thing as the code chunk above\n",
    "num_cols = 2\n",
    "num_rows = len(tracks_cols_to_plot) // num_cols + (len(tracks_cols_to_plot) % num_cols > 0)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i, column in enumerate(tracks_cols_to_plot, 1):\n",
    "    plt.subplot(num_rows, num_cols, i)\n",
    "    sns.boxplot(x=tracks_df[column])\n",
    "    plt.title(f'Box Plot of {column}')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining transformers\n",
    "\n",
    "# common transformer for continuous columns\n",
    "continuous_transformer = Pipeline([\n",
    "    ('normalizing', Normalizer(norm='l2'))\n",
    "])\n",
    "\n",
    "ranged_transformer = Pipeline([\n",
    "    ('standardizing', StandardScaler())\n",
    "])\n",
    "\n",
    "# common transformer for ordinal columns\n",
    "ordinal_transformer = Pipeline([\n",
    "    ('encoding', OrdinalEncoder())\n",
    "])\n",
    "\n",
    "# create a dictionary for column groups and their transformers\n",
    "# format of Column transformer tuples: (name of transformation, transformer, cols to transform)\n",
    "# columns that don't need processing (binary, discrete) are part of remainder='passthrough'\n",
    "column_transformers = {\n",
    "    'artists': ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('continuous_columns', continuous_transformer, artists_cols['continuous_cols']),\n",
    "            ('ranged_columns', ranged_transformer, artists_cols['ranged_cols']),\n",
    "            ('ordinal_columns', ordinal_transformer, artists_cols['ordinal_cols']),\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    ),\n",
    "    'albums': ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('continuous_columns', continuous_transformer, albums_cols['continuous_cols']),\n",
    "            ('ranged_columns', ranged_transformer, albums_cols['ranged_cols']),            \n",
    "            ('ordinal_columns', ordinal_transformer, albums_cols['ordinal_cols']),\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    ),\n",
    "    'tracks': ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('continuous_columns', continuous_transformer, tracks_cols['continuous_cols']),\n",
    "            ('ranged_columns', ranged_transformer, tracks_cols['ranged_cols']),         \n",
    "            ('ordinal_columns', ordinal_transformer, tracks_cols['ordinal_cols']),\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    ),\n",
    "    'genres': TfidfVectorizer(), # genres is the only weird one like this because it's text data being vectorized\n",
    "}\n",
    "\n",
    "# Create pipelines for each column group that will call the column transformers in the variable above\n",
    "pipelines = {\n",
    "    'artists': Pipeline([\n",
    "        ('preprocessor', column_transformers['artists']),\n",
    "    ]),\n",
    "    'albums': Pipeline([\n",
    "        ('preprocessor', column_transformers['albums']),\n",
    "    ]),\n",
    "    'tracks': Pipeline([\n",
    "        ('preprocessor', column_transformers['tracks']),\n",
    "    ]),\n",
    "    'genres': Pipeline([\n",
    "        ('preprocessor', column_transformers['genres']),\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# executing pipelines\n",
    "\n",
    "# since the data is not previously fitted in another step/pipeline, \n",
    "# .fit_transform() is used on the specified df's (the filtered down ones without id/display cols)\n",
    "artists_transformed = pipelines['artists'].fit_transform(artists_to_transform)\n",
    "albums_transformed = pipelines['albums'].fit_transform(albums_to_transform)\n",
    "tracks_transformed = pipelines['tracks'].fit_transform(tracks_to_transform)\n",
    "genres_transformed = pipelines['genres'].fit_transform(genres_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## REUSABLE TESTING CODE \n",
    "\n",
    "# with open('all_tracks_albums.json', 'w') as outfile:\n",
    "#     json.dump(all_tracks_albums, outfile, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Documentation (to be reworked)\n",
    "\n",
    "\"\"\"\n",
    "    Master dataframe documentation\n",
    "    \n",
    "    `master_df` is the master dataframe that contains all the tracks, audio features, artists, and albums data\n",
    "    post-preprocessing.\n",
    "    \n",
    "    Columns:\n",
    "    - track_id              identifier for each track\n",
    "    - track_name            name of each track\n",
    "    - album_id              identifier for each album\n",
    "    - artist_id             identifier for each artist\n",
    "    - artist_number         number of artists that perform the track\n",
    "    - explicit              True (1) or False (0) for explicit rating\n",
    "    - song_popularity       popularity of a song, value between 0 and 100\n",
    "    - preview_url           url link for 30 second preview of song\n",
    "    - danceability          danceability measure based on tempo, rhythm, etc. value between 0.0 and 1.0\n",
    "    - energy                measure of intentisty and activity, value between 0.0 and 1.0\n",
    "    - key                   key that the track is in, value ranges from -1 (no key detected) to 11\n",
    "    - loudness              overall loudness of the track in decibals, value typically betwene -60 and 0 db\n",
    "    - mode                  binary measure of modality of the track, major is 1 and minor is 0\n",
    "    - speechiness           presence of spoken words in the track, value ranges between 0.0 and 1.0\n",
    "                                [0.66, 1.0] = track probably entirely spoken words\n",
    "                                [0.33, 0.66) = track may contain both music and speech\n",
    "                                [0.0, 0.33) = track probably is music and other non-speech items\n",
    "    - acousticness          confidence measure whether track is acoustic, value ranges between 0.0 and 1.0\n",
    "    - instrumentalness      predicts whether a track contains no vocals, value ranges [0.0, 1.0]. value above 0.5\n",
    "                                meant to represent instrumental tracks, confidence is higher as value approaches 1.0 \n",
    "    - liveness              detects presence of audience. value > 0.8 is strong likelihood track is live; range [0.0, 1.0]\n",
    "    - valence               measure of musical positiveness in track, value ranges between 0.0 and 1.0\n",
    "    - tempo                 overall estimated tempo of the track (BPM)\n",
    "    - duration_ms           length of the track in milliseconds (ms) \n",
    "    - time_signature        estimated time signature of the track, value ranges between 3 and 7\n",
    "    - index column          index column (not reset, so values not unique)\n",
    "    - artist_name           name of artists performing the track\n",
    "    - artist_followers      total number of followers of the artists\n",
    "    - artist_popularity     popularity measure of artist, value [0, 100]. calcualted using popularity of all artist's tracks\n",
    "    - artist_genres         genres associated with the artists\n",
    "    - artist_img_300        300x300 image url of artist profile\n",
    "    - album_name            name of album\n",
    "    - album_type            type of album: single, album, compilation\n",
    "    - album_label           label that own the rights to the album\n",
    "    - album_popularity      popularity measure of album, value between 0 and 100\n",
    "    - album_release_date    release date of album (YYYY-MM-DD), precision may vary by track, only year (YYYY) info is retained\n",
    "    - album_tracks          number of tracks on the album\n",
    "    - album_cover_640       640x640 image url of album cover\n",
    "    - album_cover_300       300x300 image url of album cover\n",
    "    - album_cover_64        64x64 image url of album cover      \n",
    "    \n",
    "    Notes:\n",
    "    \n",
    "    Tracks may have multiple artists associated with them. In such cases, the row is exploded so each row represents\n",
    "    a single artist for the track, rest of row is duplicated and one track may be duplicated across rows.\n",
    "    \n",
    "    Artists may have multiple genres associated with them. In such cases, the rows are exploded are with the remainder \n",
    "    of values being duplicated, so each row will represent one artist and one genre. That's why some tracks will have several\n",
    "    rows for exploded artists and genres.\n",
    "    \n",
    "    In the event that an artist has no genre associated (too new or too small), similar artists' genres are fetched and are\n",
    "    used to impute the missing genres for the artists. In the event that even similar artists' genre imputing does not work\n",
    "    (similar artists are also too small/too new), it is marked off as 'genre not imputable'.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
