{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "from connection import create_spotify_oauth, get_audio_features, get_token, get_tracks, \\\n",
    "    tracks_to_df, audio_features_to_df, get_artist_info, artist_info_to_df, get_album_info, \\\n",
    "        album_info_to_df, get_similar_artists\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "import json\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, Normalizer\n",
    "from sklearn.feature_extraction.text import FeatureHasher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing tracks dataframe\n",
    "\n",
    "# merging features df to track df\n",
    "tracks_df.drop(['album_cover_640', 'album_cover_300', 'album_cover_64'], axis=1, inplace=True)\n",
    "tracks_df = pd.merge(tracks_df, tracks_features_df, how='left')\n",
    "\n",
    "tracks_df = tracks_df.explode('artist_id') \n",
    "\n",
    "# binarizing explicit column\n",
    "tracks_df['explicit'] = tracks_df['explicit'].replace({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing artists dataframe\n",
    "\n",
    "# lambda converts the columns into strings and strips of the exterior [] and '' using re, then splits the string \n",
    "# into a list based on ','\n",
    "artists_df['artist_genres'] = artists_df['artist_genres'].apply(lambda x: re.sub(r\"[\\[\\]']\", '', str(x)).split(','))\n",
    "\n",
    "# unnest the list of genres into seperate rows, rest of features are duplicated\n",
    "artists_df = artists_df.explode('artist_genres')\n",
    "\n",
    "# creates a copy of artist_df where there are no genres then drops those rows from the original df\n",
    "artists_missing_genres = artists_df.loc[artists_df['artist_genres'] == \"\"].copy()\n",
    "artists_df = artists_df[artists_df['artist_genres'] != '']\n",
    "\n",
    "# check for any artists that have missing genres\n",
    "if not artists_df.loc[artists_df['artist_genres'] == ''].empty:\n",
    "    \n",
    "    # iterates through the rows of the dataframe\n",
    "    for index, artist in artists_missing_genres.iterrows():\n",
    "        artist_id = artist['artist_id']\n",
    "        similar_artists = get_similar_artists(artist_id, token_info) # API call\n",
    "        \n",
    "        # list comprehension that fetches the artist genres for every similar artist    \n",
    "        genres_list = [similar_artist['genres'] for similar_artist in similar_artists if similar_artist['genres']]\n",
    "        \n",
    "    # convert the loop output to list\n",
    "    flattened_genres = list(chain.from_iterable(genres_list))\n",
    "\n",
    "    # converting to set so only unique values remain in list and adding it to the artists_missing_genres df\n",
    "    artists_missing_genres.at[index, 'artist_genres'] = list(set(flattened_genres)) \n",
    "\n",
    "    artists_missing_genres = artists_missing_genres.explode('artist_genres')\n",
    "\n",
    "    # if after imputation, there are still no genres, mark it off as not imputable\n",
    "    artists_missing_genres['artist_genres'].replace('','genre not imputable', inplace=True)\n",
    "\n",
    "    # concat the missing artist genres with the original df\n",
    "    artists_df = pd.concat([artists_df, artists_missing_genres], ignore_index=False)\n",
    "\n",
    "# dropping  duplicate records, this occurs if a playlist has multiple tracks from the same artist\n",
    "artists_df.drop_duplicates(subset=['artist_id', 'artist_genres'], inplace=True)\n",
    "\n",
    "# wrapping the genres in lists (for feature hashing)\n",
    "artists_df['artist_genres'] = artists_df['artist_genres'].apply(lambda x: ''.join(x)).apply(lambda x: [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing albums dataframe\n",
    "\n",
    "# converting object type column to datetime\n",
    "albums_df['album_release_date'] = pd.to_datetime(albums_df['album_release_date'], format=\"mixed\")\n",
    "albums_df['album_release_date'] = albums_df['album_release_date'].dt.year # keeping only YYYY info\n",
    "\n",
    "# categorizing album type column\n",
    "albums_df['album_type'] = albums_df['album_type'].replace({'single': 0, 'album': 1, 'compilation': 2}) # EP's count as singles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracks_df visualizations\n",
    "\n",
    "# numerical features to plot \n",
    "tracks_cols_to_plot = ['artist_number', 'song_popularity', 'danceability', 'energy',\n",
    "                'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness',\n",
    "                'liveness', 'valence', 'tempo', 'duration_ms', 'time_signature']\n",
    "\n",
    "# histogram visualizations of numerical track_df features\n",
    "num_cols = 3\n",
    "num_rows = len(tracks_cols_to_plot) // num_cols + (len(tracks_cols_to_plot) % num_cols > 0) \n",
    "\n",
    "plt.figure(figsize=(15, 15)) # creates grid\n",
    "\n",
    "# iterates through the list and creates a histogram subplot \n",
    "for i, column in enumerate(tracks_cols_to_plot, 1):\n",
    "    plt.subplot(num_rows, num_cols, i) \n",
    "    tracks_df[column].plot.hist()\n",
    "    plt.title(column)\n",
    "\n",
    "plt.tight_layout() # smushes them together\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# boxplot visualizations of numerical track_df features, pretty much same thing as the code chunk above\n",
    "num_cols = 2\n",
    "num_rows = len(tracks_cols_to_plot) // num_cols + (len(tracks_cols_to_plot) % num_cols > 0)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i, column in enumerate(tracks_cols_to_plot, 1):\n",
    "    plt.subplot(num_rows, num_cols, i)\n",
    "    sns.boxplot(x=tracks_df[column])\n",
    "    plt.title(f'Box Plot of {column}')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping columns together by type\n",
    "\n",
    "tracks_cols = {\n",
    "    'id_cols': ['track_id', 'album_id', 'artist_id'],\n",
    "    'display_cols': ['track_name', 'preview_url'],\n",
    "    'binary_cols': ['explicit', 'mode'],\n",
    "    'discrete_cols': ['artist_number'],\n",
    "    'continuous_cols': ['tempo', 'duration_ms', 'song_popularity', 'danceability', \n",
    "                        'energy', 'loudness', 'speechiness', 'acousticness', \n",
    "                        'instrumentalness', 'liveness','valence'],\n",
    "    'ordinal_cols': ['key', 'time_signature']\n",
    "}\n",
    "\n",
    "artists_cols = {\n",
    "    'id_cols': ['artist_id'],\n",
    "    'display_cols': ['artist_name', 'artist_img_300'],\n",
    "    'continuous_cols': ['artist_followers', 'artist_popularity'],\n",
    "    'categorical_cols': ['artist_genres'],\n",
    "    'ordinal_cols': []  # making an empty list for simplicity's sake in some code down below\n",
    "}\n",
    "\n",
    "albums_cols = {\n",
    "    'id_cols': ['album_id'],\n",
    "    'display_cols': ['album_name', 'album_label', 'album_cover_640', 'album_cover_300', 'album_cover_64'],\n",
    "    'discrete_cols': ['album_tracks'],\n",
    "    'ordinal_cols': ['album_release_date'],\n",
    "    'cat_lai_cols': ['album_type'],  # leave as is\n",
    "    'continuous_cols': ['album_popularity']\n",
    "}\n",
    "\n",
    "# creating filtered down df's for each group using list comprehensions that excludes id and display cols.\n",
    "# essentially it grabs every col in the df and checks if those cols are not part of id/display\n",
    "tracks_to_transform = tracks_df[[col for col in tracks_df.columns if col not in tracks_cols['id_cols'] + tracks_cols['display_cols']]]\n",
    "artists_to_transform = artists_df[[col for col in artists_df.columns if col not in artists_cols['id_cols'] + artists_cols['display_cols']]]\n",
    "albums_to_transform = albums_df[[col for col in albums_df.columns if col not in albums_cols['id_cols'] + albums_cols['display_cols']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining transformers\n",
    "\n",
    "# common transformer for continuous columns\n",
    "continuous_transformer = Pipeline([\n",
    "    ('standardizing', StandardScaler())\n",
    "])\n",
    "\n",
    "# common transformer for ordinal columns\n",
    "ordinal_transformer = Pipeline([\n",
    "    ('encoding', OrdinalEncoder())\n",
    "])\n",
    "\n",
    "text_transformer = Pipeline([\n",
    "    ('hashing', FeatureHasher(n_features=2**20,\n",
    "                              input_type='string'))\n",
    "])\n",
    "\n",
    "# create a dictionary for column groups and their transformers\n",
    "# format of Column transformer tuples: (name of transformation, transformer, cols to transform)\n",
    "# columns that don't need processing (binary, discrete) are part of remainder='passthrough'\n",
    "column_transformers = {\n",
    "    'artists': ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('continuous', continuous_transformer, artists_cols['continuous_cols']),\n",
    "            ('ordinal', ordinal_transformer, artists_cols['ordinal_cols']),\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    ),\n",
    "    'albums': ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('continuous', continuous_transformer, albums_cols['continuous_cols']),\n",
    "            ('ordinal', ordinal_transformer, albums_cols['ordinal_cols']),\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    ),\n",
    "    'tracks': ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('continuous', continuous_transformer, tracks_cols['continuous_cols']),\n",
    "            ('ordinal', ordinal_transformer, tracks_cols['ordinal_cols']),\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "}\n",
    "\n",
    "# Create pipelines for each column group that will call the column transformers in the variable above\n",
    "pipelines = {\n",
    "    'artists': Pipeline([\n",
    "        ('preprocessor', column_transformers['artists']),\n",
    "    ]),\n",
    "    'albums': Pipeline([\n",
    "        ('preprocessor', column_transformers['albums']),\n",
    "    ]),\n",
    "    'tracks': Pipeline([\n",
    "        ('preprocessor', column_transformers['tracks']),\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature hashing artist genres \n",
    "# (will need to turn this into a function that passes into column transformer)\n",
    "\n",
    "artists_genres_dict = artists_df['artist_genres'].to_dict() # convert to dict\n",
    "X = text_transformer.fit_transform(artists_df['artist_genres']) # apply transformer\n",
    "X = X.toarray() # convert output to array\n",
    "X_ = pd.DataFrame(data=X, columns=[f'genre_{i}' for i in range(X.shape[1])], index=artists_df.index) # convert array to df\n",
    "artists_df = pd.concat([artists_df, X_], axis=1) # merge artist df with the hashed genres\n",
    "artists_df.drop(['artist_genres'], axis=1, inplace=True) # dropped the og genre column since it's not needed anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# executing pipelines\n",
    "\n",
    "# since the data is not previously fitted in another step/pipeline, \n",
    "# .fit_transform() is used on the specified df's (the filtered down ones without id/display cols)\n",
    "artists_transformed = pipelines['artists'].fit_transform(artists_to_transform)\n",
    "albums_transformed = pipelines['albums'].fit_transform(albums_to_transform)\n",
    "tracks_transformed = pipelines['tracks'].fit_transform(tracks_to_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# executing pipelines\n",
    "\n",
    "# since the data is not previously fitted in another step/pipeline, \n",
    "# .fit_transform() is used on the specified df's (the filtered down ones without id/display cols)\n",
    "artists_transformed = pipelines['artists'].fit_transform(artists_to_transform)\n",
    "albums_transformed = pipelines['albums'].fit_transform(albums_to_transform)\n",
    "tracks_transformed = pipelines['tracks'].fit_transform(tracks_to_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding feature names back to df's\n",
    "artists_transformed = pd.DataFrame(artists_transformed, columns = pipelines['artists'].get_feature_names_out())\n",
    "albums_transformed = pd.DataFrame(albums_transformed, columns = pipelines['albums'].get_feature_names_out())\n",
    "tracks_transformed = pd.DataFrame(tracks_transformed, columns = pipelines['tracks'].get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating master dataframe\n",
    "\n",
    "# resetting indexes (to avoid errors during merge)\n",
    "artists_df.reset_index(inplace=True)\n",
    "albums_df.reset_index(inplace=True)\n",
    "tracks_df.reset_index(inplace=True)\n",
    "\n",
    "# to avoid duplicate columns in master_df merging below\n",
    "artists_df.drop(['artist_followers','artist_popularity'], axis=1, inplace=True)\n",
    "\n",
    "# remerging id / display cols back with the transformed df's\n",
    "artists_post_transform = pd.concat([artists_df[artists_cols['id_cols'] + artists_cols['display_cols']], \n",
    "                                    artists_transformed, artists_df], axis=1)\n",
    "albums_post_transform = pd.concat([albums_df[albums_cols['id_cols'] + albums_cols['display_cols']], \n",
    "                                   albums_transformed], axis=1)\n",
    "tracks_post_transform = pd.concat([tracks_df[tracks_cols['id_cols'] + tracks_cols['display_cols']], \n",
    "                                   tracks_transformed], axis=1)\n",
    "\n",
    "# remerging hashed artist genre columns\n",
    "artists_post_transform = artists_post_transform.loc[:,~artists_post_transform.columns.duplicated()]\n",
    "\n",
    "# merge tracks and artists on 'artist_id'\n",
    "master_df = pd.merge(tracks_post_transform, artists_post_transform, on='artist_id', how='inner')\n",
    "\n",
    "# merge the result with albums on 'album_id'\n",
    "master_df = pd.merge(master_df, albums_post_transform, on='album_id', how='inner')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
